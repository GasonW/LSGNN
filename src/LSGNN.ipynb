{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Activation, Concatenate, Flatten, Dropout, Reshape, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv1D\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers.pooling import MaxPool2D, MaxPool1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import mae, categorical_accuracy\n",
    "from keras_metric import neg_sparse_categorical_crossentropy, precision, recall\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from gensim.models import Word2Vec as w2v\n",
    "\n",
    "import sys, os\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from dataloder import encode_samples, pad_samples\n",
    "from mymetric import my_confusion_matrix, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSGNN():\n",
    "    def __init__(self):\n",
    "        # Input Shape\n",
    "        self.sent_len = 100\n",
    "        self.sent_dim = 32\n",
    "        self.sent_shape = (self.sent_len, self.sent_dim)\n",
    "        self.extra_knowledge = 8\n",
    "        self.drop = 0.4\n",
    "        self.filter_num = 40\n",
    "        self.fileter_length=[2,3,4,5] \n",
    "        self.hidden_num = 40\n",
    "        self.cnn_features_shape = (320,)\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.8)\n",
    "        \n",
    "        \"\"\"Build the knowledge guidance subnetwork\"\"\"\n",
    "        self.knowledge_guidance = self.build_knowledge_guidance()\n",
    "        self.knowledge_guidance.name = 'kd'\n",
    "        \n",
    "        \"\"\"Build the rumor detector\"\"\"\n",
    "        self.rumor_detector = self.build_rumor_detector()\n",
    "        self.rumor_detector.name = 'rd'\n",
    "        \n",
    "        \"\"\"Build the feature generator\"\"\"\n",
    "        self.feature_generator = self.build_feature_generator_CNN() \n",
    "        \n",
    "        \"\"\"Build the combined model\"\"\"\n",
    "        text = Input(shape=self.sent_shape, name='combined_input')\n",
    "        text_feature = self.feature_generator(text)\n",
    "        \n",
    "        \"\"\"The output of the combined model are consist of rumor detector output and event detector\"\"\"\n",
    "        is_rumor = self.rumor_detector(text_feature)\n",
    "        re_constract_knowledge = self.knowledge_guidance(text_feature)\n",
    "        \n",
    "        \"\"\"Build and compile the combined model\"\"\"\n",
    "        self.combined = Model(text, [is_rumor, re_constract_knowledge])\n",
    "        self.combined.compile(loss=['binary_crossentropy','kullback_leibler_divergence'],\n",
    "            optimizer=optimizer,\n",
    "            metrics={'rd':'acc',\n",
    "                     'kd':'mae'})\n",
    "                \n",
    "\n",
    "    def build_feature_generator_CNN(self):\n",
    "        text = Input(shape=self.sent_shape)\n",
    "\n",
    "        conv1 = Conv1D(self.filter_num, kernel_size=(self.fileter_length[0]), input_shape=(self.sent_len,self.sent_dim), activation=\"relu\")(text)\n",
    "        conv2 = Conv1D(self.filter_num, kernel_size=(self.fileter_length[1]), input_shape=(self.sent_len,self.sent_dim), activation=\"relu\")(text)\n",
    "        conv3 = Conv1D(self.filter_num, kernel_size=(self.fileter_length[2]), input_shape=(self.sent_len,self.sent_dim), activation=\"relu\")(text)\n",
    "        conv4 = Conv1D(self.filter_num, kernel_size=(self.fileter_length[3]), input_shape=(self.sent_len,self.sent_dim), activation=\"relu\")(text)\n",
    "\n",
    "        maxp1 = GlobalMaxPooling1D()(conv1)\n",
    "        maxp2 = GlobalMaxPooling1D()(conv2)\n",
    "        maxp3 = GlobalMaxPooling1D()(conv3)\n",
    "        maxp4 = GlobalMaxPooling1D()(conv4)\n",
    "\n",
    "        conv5 = Conv1D(self.filter_num, kernel_size=(3), activation=\"relu\")(conv1) \n",
    "        conv6 = Conv1D(self.filter_num, kernel_size=(3), activation=\"relu\")(conv2) \n",
    "        conv7 = Conv1D(self.filter_num, kernel_size=(3), activation=\"relu\")(conv3) \n",
    "        conv8 = Conv1D(self.filter_num, kernel_size=(3), activation=\"relu\")(conv4) \n",
    "\n",
    "        maxp5 = GlobalMaxPooling1D()(conv5)\n",
    "        maxp6 = GlobalMaxPooling1D()(conv6)\n",
    "        maxp7 = GlobalMaxPooling1D()(conv7)\n",
    "        maxp8 = GlobalMaxPooling1D()(conv8)\n",
    "        \n",
    "        text_feature = Concatenate(axis=1, name='cnn_feature')([maxp1, maxp2, maxp3, maxp4, \n",
    "                                                                maxp5, maxp6, maxp7, maxp8])        \n",
    "        model = Model(inputs=text, outputs=text_feature)\n",
    "        return model\n",
    "        \n",
    "    \n",
    "    def build_rumor_detector(self):\n",
    "        text_feature = Input(shape=self.cnn_features_shape)\n",
    "        \n",
    "        x = Dense(64, activation='relu')(text_feature)\n",
    "        output = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        model = Model(inputs=text_feature, outputs = output)\n",
    "        return model\n",
    "    \n",
    "    def build_knowledge_guidance(self):\n",
    "        text_feature = Input(shape=self.cnn_features_shape)\n",
    "        \n",
    "        x = Dense(self.extra_knowledge,activation='linear')(text_feature)\n",
    "        x = Dense(self.extra_knowledge, activation='softmax')(x)\n",
    "        model = Model(inputs=text_feature, outputs=x)\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ============================ Train Methods ================================ #\n",
    "    def train_global(self, X_train, y_rumor_train, y_ek_train, X_val, y_rumor_val, y_ek_val, epoches=200, batch_size=128):\n",
    "        timestr = time.strftime('%m%d@%H')\n",
    "        param_path = './'\n",
    "        global_param_path = param_path + timestr + '_lsgnn.hdf5'\n",
    "\n",
    "        earlystop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "        global_checkpoint = ModelCheckpoint(global_param_path, monitor='val_loss', \n",
    "                                            verbose=0, save_best_only=True, mode='auto')\n",
    "        global_callbacks_list = [global_checkpoint, earlystop]\n",
    "\n",
    "        g_loss = self.combined.fit(X_train, [y_rumor_train, y_ek_train],\n",
    "            batch_size=batch_size, validation_data=[X_val, [y_rumor_val, y_ek_val]], \n",
    "            epochs=epoches, verbose=2, shuffle=True, callbacks=global_callbacks_list)\n",
    "        return g_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SGBNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text_cut, maxlen=100):\n",
    "    w2v_path = '../model/word_emb_32.ell'\n",
    "    w2vmodel = w2v.load(w2v_path)\n",
    "    X = encode_samples(text_cut, w2vmodel)\n",
    "    X = pad_samples(X, maxlen)\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "def encode_label(label):\n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features_name():\n",
    "    feature_list = []\n",
    "    f = open(\"../model/manual_feature.txt\", \"r\")\n",
    "    for line in f:\n",
    "        feature_list.append(line.strip())\n",
    "    f.close()\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_features = ['interactivity', 'interestingness', 'moving', 'persuasive', 'logic', 'readability', 'formality','Integrity1']\n",
    "text_features = list(set(load_features_name()).difference(set(high_features)))\n",
    "\n",
    "data = pd.read_csv('../data/ictmcg_train.csv',header=0)\n",
    "text_cut_train = data.seg.values.tolist()\n",
    "y_rumor_train = data.label.values.tolist()\n",
    "y_ek_train = data[high_features].values.tolist()\n",
    "X_train = encode_text(text_cut_train)\n",
    "y_rumor_train = encode_label(y_rumor_train)\n",
    "y_ek_train = encode_label(y_ek_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = pd.read_csv('../data/ictmcg_val.csv',header=0)\n",
    "text_cut_val = data_val.seg.values.tolist()\n",
    "y_rumor_val = data_val.label.values.tolist()\n",
    "y_ek_val = data_val[high_features].values.tolist()\n",
    "X_val = encode_text(text_cut_val)\n",
    "y_rumor_val = encode_label(y_rumor_val)\n",
    "y_ek_val = encode_label(y_ek_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsgnn = LSGNN()\n",
    "loss = lsgnn.train_global(X_train, y_rumor_train, y_ek_train, \n",
    "                 X_val, y_rumor_val, y_ek_val, epoches=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('../data/ictmcg_test.csv',header=0)\n",
    "text_cut_test = data_test.seg.values.tolist()\n",
    "y_rumor_test = data_test.label.values.tolist()\n",
    "y_ek_test = data_test[high_features].values.tolist()\n",
    "X_test = encode_text(text_cut_test)\n",
    "y_rumor_test = encode_label(y_rumor_test)\n",
    "y_ek_test = encode_label(y_ek_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_eva(evalist, metrics_name):\n",
    "    print('===========================')\n",
    "    for i in range(len(metrics_name)):\n",
    "        print('%s: %.4f' %(metrics_name[i],evalist[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_eva = lsgnn.combined.evaluate(X_test, [y_rumor_test, y_ek_test])\n",
    "y_rumor_pred, y_ek_pred = sgbnn.combined.predict(X_test)\n",
    "y_rumor_predict = [1 if x > 0.5 else 0 for x in y_rumor_pred]\n",
    "show_eva(global_eva, sgbnn.combined.metrics_names)\n",
    "summary(y_rumor_test, y_rumor_predict)\n",
    "my_confusion_matrix(y_rumor_test, y_rumor_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
